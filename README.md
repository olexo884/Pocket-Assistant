# ğŸ¤– Pocket Assistant â€” Experimental Autonomous Voice Assistant

**Pocket Assistant** is an experimental autonomous voice assistant prototype built around **ESP32**, combining embedded hardware, UI design, audio processing, and an AI-powered backend.

The project is split into two tightly connected parts:

* ğŸ”Œ **ESP32 Client (Firmware / PlatformIO)** â€” handles UI, menu navigation, audio input/output, Bluetooth, and communication with the server.
* ğŸ–¥ï¸ **Python Server (Flask)** â€” processes voice input, communicates with OpenAI, and generates both text and voice responses.

This project focuses on **real hardware interaction**, not just software simulation.

---

## ğŸ¨ Design & Hardware References

* ğŸ§© **UI / UX (Figma):**
  [https://www.figma.com/design/nQ5vYbNvR1JXNJ7YZx3jHn/Pocket-Assistant-%E2%80%94-Experimental-Autonomous-Voice-Assistant](https://www.figma.com/design/nQ5vYbNvR1JXNJ7YZx3jHn/Pocket-Assistant-%E2%80%94-Experimental-Autonomous-Voice-Assistant)

* ğŸ› ï¸ **Hardware schematic (EasyEDA):**
  [https://oshwlab.com/olexo884/pocket-assistant-experimental-autonomous-voice-assistant](https://oshwlab.com/olexo884/pocket-assistant-experimental-autonomous-voice-assistant)

---

## âœ¨ Core Features

### ğŸ“Ÿ Device Interface & Menu System

The device is controlled using a **rotary encoder with a button** and additional physical buttons.
All interaction happens directly on the device â€” **no phone or PC required**.

The menu allows you to:

* ğŸ“¶ Configure **Wi-Fi** (SSID, password, connection status)
* ğŸ§  Adjust **AI-related settings**
* ğŸ•’ Manually set **date and time**
* ğŸµ Use **Bluetooth audio mode** to listen to music

---

### ğŸ”Š Bluetooth Audio

The device works as a Bluetooth speaker.

* ğŸ“¡ **Bluetooth name:** `PocketAssistantBT`
* ğŸ”ˆ Audio output via **MAX98357A (I2S amplifier) + speaker**

---

## ğŸ™ï¸ Voice Assistant Mode (ESP32 â†’ Server)

Once the device is connected to Wi-Fi, it can work as a full voice assistant.

**How it works:**

* âºï¸ Long press on the encoder button starts voice interaction
* ğŸ¤ ESP32 records an audio file
* ğŸŒ Audio is sent to the server
* ğŸ§  Server pipeline:

  * Voice â†’ Text (STT)
  * Text â†’ OpenAI
  * Text â†’ Voice (TTS)
* ğŸ“¥ ESP32 receives:

  * recognized input text
  * AI response text
  * audio response
* ğŸ“º Device:

  * displays text on OLED
  * plays audio via speaker

â¡ï¸ This creates a full **voice â†’ AI â†’ voice** pipeline using real hardware.

---

## ğŸ”§ Hardware Overview (Prototype)

This is a **working prototype**, not a finalized commercial design.

Main components:

* âš™ï¸ ESP32
* ğŸ–¥ï¸ 0.96" monochrome OLED display (128Ã—64)
* ğŸ™ï¸ **INMP441** I2S microphone
* ğŸ”Š **MAX98357A** I2S mono amplifier
* ğŸ”ˆ Speaker (4Î© / 8Î©)
* ğŸ›ï¸ Rotary encoder with button
* â¹ï¸ Control buttons
* ğŸ”‹ Li-ion 3.7V battery + charging/protection
* ğŸ’¾ Optional SD-card module

Power management and PCB layout are still evolving.

---

## ğŸ—‚ï¸ Project Structure (Recommended)

```
pocket-assistant/
  firmware-esp32/   â†’ ESP32 firmware (PlatformIO)
  server/           â†’ Python Flask backend
  docs/             â†’ diagrams, screenshots, photos
  README.md
```

---

## ğŸ§© System Architecture (High Level)

1. ğŸ“¶ ESP32 connects to Wi-Fi
2. âºï¸ User presses and holds encoder button
3. ğŸ¤ ESP32 records voice
4. ğŸŒ Audio is sent to Flask server
5. ğŸ§  Server performs:

   * Speech-to-Text
   * OpenAI request
   * Text-to-Speech
6. ğŸ“¥ ESP32 receives response
7. ğŸ“º Text displayed, ğŸ”Š audio played

---

## ğŸ–¥ï¸ Server Setup (Python / Flask)

The backend server handles AI and audio processing.

OpenAI client initialization:

```python
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
```

### ğŸ”‘ OpenAI API Key Setup

1. Create an API key in OpenAI dashboard
2. Add it to `.env` inside `server` folder:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

> âš ï¸ `.env` is excluded from git.

---

## ğŸ”Œ ESP32 Firmware

* Built with **PlatformIO**
* Handles:

  * ğŸ¨ UI rendering
  * ğŸ›ï¸ Button & encoder input
  * ğŸ¤ Audio recording / playback
  * ğŸ“¶ Wi-Fi & Bluetooth
  * ğŸŒ Server communication

Most logic is currently monolithic due to rapid prototyping.

---

## ğŸš§ Project Status

* ğŸ§ª Experimental R&D project
* âœ… Functional hardware & software
* ğŸ§± Some monolithic code by design
* ğŸ› ï¸ Planned improvements:

  * Code modularization
  * Power optimization
  * PCB refinement
  * UI polish & animation

---

## ğŸŒ Why This Project Matters

This project demonstrates:

* âš¡ Embedded systems (ESP32)
* ğŸ”Œ Real hardware interaction
* ğŸ§ Audio processing (I2S)
* ğŸŒ Client-server architecture
* ğŸ¤– AI in physical devices
* ğŸ¨ UI/UX beyond pure software

**Hands-on. Practical. Real.**

---

## ğŸ‘¤ Author

**Oleksii Shevchuk**
ESP32 â€¢ C++ â€¢ Python â€¢ EasyEDA â€¢ IoT / Embedded

---
